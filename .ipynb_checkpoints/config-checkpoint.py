# 获取时间戳的最大尝试次数
TIMESTAMP_MAX_TRY = 6
# 握手包的询问提示词（已注释，改为从文件读取）
# HANDSHAKE_QUESTION = "Hello! I'm planning a detailed 7-day itinerary for a trip to Singapore, focusing on a deep dive into its culinary scene and modern architecture. Could you act as my expert local guide for this planning session?"

# 问题文件配置
QUESTION_FILES = {
    "philosophy": "data/question/philosophy.txt",
    "art": "data/question/art.txt", 
    "general": "data/question/general.txt"
}

# 客户端日志路径
CLIENT_LOG_PATH = "data/logs/client"
# 服务端日志路径
SERVER_LOG_PATH = "data/logs/server"
# 隐写密钥
STEGO_KEY="what the fuck"
# 隐写密文路径
STEGO_SECRET_MESSAGE_PATH="data/stego/secret_bits.txt"
# 隐写解密文件路径
STEGO_DECRYPT_MESSAGE_PATH="data/stego/decrypted_bits.txt"
# Agent模型配置
SERVER_URL="http://localhost:9999"
AGENT_MODEL_CONFIG={ #格式为litellm库，https://docs.litellm.ai/docs/providers，在此查看名称格式
  "model":"gemini/gemini-2.0-flash",# deepseek/deepseek-chat,
  # 需要在项目根目录下创建.env文件来添加APIKEY！！，Gemini的APIKEY格式为GEMINI_API_KEY=Token，deepseek的APIKEY格式为DEEPSEEK_API_KEY=Token，openai的APIKEY格式为OPENAI_API_KEY=Token
}
EVALUATION_MODEL_CONFIG={
  "model_name_or_path":"/root/autodl-tmp/Llama-3.2-3B-Instruct",# Meta-Llama-3-8B-Instruct
}
# 隐写模型配置
LLM_CONFIG={
  "model_name_or_path":"/root/autodl-tmp/Meta-Llama-3-8B-Instruct",# Meta-Llama-3-8B-Instruct
  "precision": "half",
  "topk":0,
  "role":"user",
  "prompt_template":"chat",
  "max_new_tokens":256,
  "base_prompt":"You are a highly curious and detail-oriented person. Your goal is to ask insightful, open-ended follow-up questions based on the expert's last response.\n\n# Conversation History:\n{conversation_history}\n\nYour Task:\nBased ONLY on the expert's LAST answer provided above, formulate your NEXT question. Your question must be in English, be detailed, and seek specific information. For example, ask for comparisons (\"How does that compare to...\"), historical context (\"What's the story behind...\"), specific recommendations (\"Could you name three specific hawker stalls for...\"), or 'a day in the life' examples. Do not repeat previous questions. Be creative and make your question substantial."
}
# 隐写算法配置
ALGORITHM_CONFIG={
    "algorithm": "stability_based",#使用的算法，目前支持discop,discop_base,ac,differential_based,binary_based,stability_based
    "seed":42,#随机种子
    # 具体的算法配置
    "discop":{
      "precision":52,
      "input_key":"30783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031",
      "sample_seed_prefix":"73616d706c65",
      "input_nonce":"00000000000000000000000000000000",
    },
    "discop_base":{
      "precision":52,
      "input_key":"30783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031",
      "sample_seed_prefix":"73616d706c65",
      "input_nonce":"00000000000000000000000000000000",
    },
   "ac": {
      "precision":52,
    },
    # Artifacts Framework算法配置
    "differential_based":{
      "precision":52,
      "input_key":"30783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031",
      "sample_seed_prefix":"73616d706c65",
      "input_nonce":"00000000000000000000000000000000",
    },
    "binary_based":{
      "precision":52,
      "input_key":"30783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031",
      "sample_seed_prefix":"73616d706c65",
      "input_nonce":"00000000000000000000000000000000",
    },
    "stability_based":{
      "precision":52,
      "input_key":"30783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031307830313078303130783031",
      "sample_seed_prefix":"73616d706c65",
      "input_nonce":"00000000000000000000000000000000",
    }
}
  
